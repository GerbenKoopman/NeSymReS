{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the root directory of the nesymres module to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example for performing symbolic regression for a set of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libtorch_cpu.so: cannot enable executable stack as shared object requires: Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnesymres\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchitectures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnesymres\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metadata_hdf5\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnesymres\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitParams, NNEquation, BFGSParams\n",
      "File \u001b[0;32m~/Code/IEinAI Project/NeSymReS/src/nesymres/architectures/model.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/nesym/lib/python3.8/site-packages/torch/__init__.py:290\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    289\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: libtorch_cpu.so: cannot enable executable stack as shared object requires: Invalid argument"
     ]
    }
   ],
   "source": [
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import torch\n",
    "from sympy import lambdify\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load equation configuration and architecture configuration\n",
    "import omegaconf\n",
    "with open('100M/eq_setting.json', 'r') as json_file:\n",
    "  eq_setting = json.load(json_file)\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"100M/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"../weights/100M.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.3.3 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../weights/100M.ckpt`\n"
     ]
    }
   ],
   "source": [
    "## Load architecture, set into eval mode, and pass the config parameters\n",
    "model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "model.eval()\n",
    "if torch.cuda.is_available(): \n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from nesymres.architectures.beam_search import generate_multiple_beams\n",
    "\n",
    "# Define multiple beam search configurations for ablation study\n",
    "beam_configs = [\n",
    "    {\"beam_size\": 1, \"length_penalty\": 1.0, \"max_len\": 50},\n",
    "    {\"beam_size\": 3, \"length_penalty\": 1.0, \"max_len\": 75},\n",
    "    {\"beam_size\": 5, \"length_penalty\": 1.0, \"max_len\": 100},\n",
    "    {\"beam_size\": 10, \"length_penalty\": 1.0, \"max_len\": 150},\n",
    "]\n",
    "\n",
    "fitfunc = partial(model.fitfunc, cfg_params=params_fit, beam_configs=beam_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m n_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#To get best results make sure that your support inside the max and mix support\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m max_supp \u001b[38;5;241m=\u001b[39m \u001b[43mcfg\u001b[49m\u001b[38;5;241m.\u001b[39mdataset_train\u001b[38;5;241m.\u001b[39mfun_support[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[1;32m      7\u001b[0m min_supp \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mdataset_train\u001b[38;5;241m.\u001b[39mfun_support[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(number_of_points,\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(eq_setting[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m])))\u001b[38;5;241m*\u001b[39m(max_supp\u001b[38;5;241m-\u001b[39mmin_supp)\u001b[38;5;241m+\u001b[39mmin_supp\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "# Create points from an equation\n",
    "number_of_points = 500\n",
    "n_variables = 2\n",
    "\n",
    "#To get best results make sure that your support inside the max and mix support\n",
    "max_supp = cfg.dataset_train.fun_support[\"max\"] \n",
    "min_supp = cfg.dataset_train.fun_support[\"min\"]\n",
    "X = torch.rand(number_of_points,len(list(eq_setting[\"total_variables\"])))*(max_supp-min_supp)+min_supp\n",
    "X[:,n_variables:] = 0\n",
    "target_eq = \"x_1*sin(x_1)+cos(x_2)\" #Use x_1,x_2 and x_3 as independent variables\n",
    "X_dict = {x:X[:,idx].cpu() for idx, x in enumerate(eq_setting[\"total_variables\"])}\n",
    "y_pre_noise = lambdify(\",\".join(eq_setting[\"total_variables\"]), target_eq)(**X_dict)\n",
    "\n",
    "### Added Noise\n",
    "noise_std = 0.1   #Standard deviation of the noise\n",
    "noise = np.random.normal(loc=0.0, scale=noise_std, size=y.shape)\n",
    "y = y_pre_noise + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([500, 3])\n",
      "y shape:  torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of the encoder: 0.0001024GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Memory footprint of the encoder: 0.0002048GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Memory footprint of the encoder: 6.144e-05GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n"
     ]
    }
   ],
   "source": [
    "output = fitfunc(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'config': {'beam_size': 5, 'length_penalty': 1.0, 'max_len': 100},\n",
       "  'output': {'all_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))',\n",
       "    'x_1*cos(x_1 + 4.71238898953286) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + 1.00000000286262*cos(x_2)',\n",
       "    '1.00000000688604*x_1*sin(x_1) + cos(x_2)',\n",
       "    '(((x_1)+(cos(x_2)))*(sin(x_1)))'],\n",
       "   'all_bfgs_loss': [0.0, 1.4166446e-14, 0.0, 0.0, 0.7319734],\n",
       "   'best_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))'],\n",
       "   'best_bfgs_loss': [0.0]}},\n",
       " {'config': {'beam_size': 10, 'length_penalty': 0.8, 'max_len': 150},\n",
       "  'output': {'all_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))',\n",
       "    'x_1*cos(x_1 - 1.57079631450141) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + 1.00000003054959*cos(x_2)',\n",
       "    '0.999999976838865*x_1*sin(x_1) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + cos(x_2 + 4.08816707536777e-9)',\n",
       "    '(x_1 + 8.19135437257756e-9)*sin(x_1) + cos(x_2)',\n",
       "    '(((x_1)+(cos(x_2)))*(sin(x_1)))',\n",
       "    '(((x_1)*(sin(x_1)))+(sin(cos(x_2))))',\n",
       "    'x_1*sin(x_1) + cos(1.00000000756742*x_2)',\n",
       "    'x_1*sin(x_1 + 1.13542482258025e-8) + cos(x_2)'],\n",
       "   'all_bfgs_loss': [0.0,\n",
       "    1.164252e-12,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.7319734,\n",
       "    0.008233367,\n",
       "    0.0,\n",
       "    0.0],\n",
       "   'best_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))'],\n",
       "   'best_bfgs_loss': [0.0]}},\n",
       " {'config': {'beam_size': 3, 'length_penalty': 1.2, 'max_len': 80},\n",
       "  'output': {'all_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))',\n",
       "    'x_1*cos(x_1 + 4.71238887588783) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + 1.00000004133854*cos(x_2)'],\n",
       "   'all_bfgs_loss': [0.0, 1.4166446e-14, 0.0],\n",
       "   'best_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))'],\n",
       "   'best_bfgs_loss': [0.0]}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
