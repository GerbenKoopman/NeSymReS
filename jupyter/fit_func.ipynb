{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the root directory of the nesymres module to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example for performing symbolic regression for a set of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import torch\n",
    "from sympy import lambdify\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load equation configuration and architecture configuration\n",
    "import omegaconf\n",
    "with open('100M/eq_setting.json', 'r') as json_file:\n",
    "  eq_setting = json.load(json_file)\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"100M/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"../weights/100M.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerben-koopman/miniconda3/envs/nesymres/lib/python3.8/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.3.3 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../weights/100M.ckpt`\n"
     ]
    }
   ],
   "source": [
    "## Load architecture, set into eval mode, and pass the config parameters\n",
    "model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "model.eval()\n",
    "if torch.cuda.is_available(): \n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from nesymres.architectures.beam_search import generate_multiple_beams\n",
    "\n",
    "# Define multiple beam search configurations for ablation study\n",
    "beam_configs = [\n",
    "    {\"beam_size\": 5, \"length_penalty\": 1.0, \"max_len\": 100},\n",
    "    {\"beam_size\": 10, \"length_penalty\": 0.8, \"max_len\": 150},\n",
    "    {\"beam_size\": 3, \"length_penalty\": 1.2, \"max_len\": 80},\n",
    "]\n",
    "\n",
    "fitfunc = partial(model.fitfunc, cfg_params=params_fit, beam_configs=beam_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points from an equation\n",
    "number_of_points = 500\n",
    "n_variables = 2\n",
    "\n",
    "#To get best results make sure that your support inside the max and mix support\n",
    "max_supp = cfg.dataset_train.fun_support[\"max\"] \n",
    "min_supp = cfg.dataset_train.fun_support[\"min\"]\n",
    "X = torch.rand(number_of_points,len(list(eq_setting[\"total_variables\"])))*(max_supp-min_supp)+min_supp\n",
    "X[:,n_variables:] = 0\n",
    "target_eq = \"x_1*sin(x_1)+cos(x_2)\" #Use x_1,x_2 and x_3 as independent variables\n",
    "X_dict = {x:X[:,idx].cpu() for idx, x in enumerate(eq_setting[\"total_variables\"])} \n",
    "y = lambdify(\",\".join(eq_setting[\"total_variables\"]), target_eq)(**X_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([500, 3])\n",
      "y shape:  torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerben-koopman/studie/nesymres/src/nesymres/architectures/model.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X,device=self.device).unsqueeze(0)\n",
      "/home/gerben-koopman/studie/nesymres/src/nesymres/architectures/model.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y,device=self.device).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of the encoder: 0.0001024GB \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerben-koopman/miniconda3/envs/nesymres/lib/python3.8/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Memory footprint of the encoder: 0.0002048GB \n",
      "\n",
      "Memory footprint of the encoder: 0.0002048GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Memory footprint of the encoder: 6.144e-05GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Memory footprint of the encoder: 6.144e-05GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Loss constructed, starting new BFGS optmization...\n"
     ]
    }
   ],
   "source": [
    "output = fitfunc(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'config': {'beam_size': 5, 'length_penalty': 1.0, 'max_len': 100},\n",
       "  'output': {'all_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))',\n",
       "    'x_1*sin(x_1) + 0.999999996114992*cos(x_2)',\n",
       "    '(((x_1)*(sin(x_1)))+(sin(cos(x_2))))',\n",
       "    'x_1*cos(x_1 + 4.712388990822) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + cos(x_2 - 1.4834446309234e-8)'],\n",
       "   'all_bfgs_loss': [0.0, 0.0, 0.008284129, 2.4116709e-14, 0.0],\n",
       "   'best_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))'],\n",
       "   'best_bfgs_loss': [0.0]}},\n",
       " {'config': {'beam_size': 10, 'length_penalty': 0.8, 'max_len': 150},\n",
       "  'output': {'all_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))',\n",
       "    'x_1*sin(x_1) + 0.999999975725089*cos(x_2)',\n",
       "    '(((x_1)*(sin(x_1)))+(sin(cos(x_2))))',\n",
       "    'x_1*cos(x_1 + 4.71238894503717) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + cos(x_2 + 2.94125416714029e-9)',\n",
       "    '(x_1 - 1.43250354980862e-9)*sin(x_1) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + cos(0.99999999046535*x_2)',\n",
       "    '1.00000001471522*x_1*sin(x_1) + cos(x_2)',\n",
       "    'x_1*sin(x_1) + sin(x_2 - 4.71238899555651)',\n",
       "    'x_1*sin(x_1) + cos(x_2) + 1.12637834615015e-8'],\n",
       "   'all_bfgs_loss': [0.0,\n",
       "    0.0,\n",
       "    0.008284129,\n",
       "    2.4116709e-14,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    8.002293e-15,\n",
       "    7.077672e-18],\n",
       "   'best_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))'],\n",
       "   'best_bfgs_loss': [0.0]}},\n",
       " {'config': {'beam_size': 3, 'length_penalty': 1.2, 'max_len': 80},\n",
       "  'output': {'all_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))',\n",
       "    'x_1*sin(x_1) + 0.999999996123279*cos(x_2)',\n",
       "    '(((x_1)*(sin(x_1)))+(sin(cos(x_2))))'],\n",
       "   'all_bfgs_loss': [0.0, 0.0, 0.008284129],\n",
       "   'best_bfgs_preds': ['(((x_1)*(sin(x_1)))+(cos(x_2)))'],\n",
       "   'best_bfgs_loss': [0.0]}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nesymres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
