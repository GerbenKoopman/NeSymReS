# Original NESYMRES Configuration
# This is the original configuration format before wrapper integration

# Data paths - use available datasets
train_path: data/raw_datasets/100
val_path: data/raw_datasets/50

# Basic training parameters
wandb: False  # Disable wandb for original training demo
wandb_project: "nesymres"
num_of_workers: 4
batch_size: 8  # Smaller batch size for local training
epochs: 3      # Short training for demonstration
val_check_interval: 1.0
precision: 32  # Use 32-bit for stability
gpu: 0        # Single GPU or 0 for CPU

# Dataset configurations
dataset_train:
  total_variables: #Do not fill - populated automatically
  total_coefficients: #Do not fill - populated automatically
  max_number_of_points: 400  # Reduced for faster training
  type_of_sampling_points: logarithm
  predict_c: True
  fun_support:
    max: 10
    min: -10
  constants:
    num_constants: 3
    additive:
      max: 2
      min: -2
    multiplicative:
      max: 2
      min: -2

dataset_val:
  total_variables: #Do not fill
  total_coefficients: #Do not fill
  max_number_of_points: 200
  type_of_sampling_points: constant
  predict_c: True
  fun_support:
    max: 10
    min: -10
  constants:
    num_constants: 3
    additive:
      max: 2
      min: -2
    multiplicative:
      max: 5
      min: 0.1

dataset_test:
  total_variables: #Do not fill
  total_coefficients: #Do not fill
  max_number_of_points: 200
  type_of_sampling_points: constant
  predict_c: False
  fun_support:
    max: 10
    min: -10
  constants:
    num_constants: 3
    additive:
      max: 2
      min: -2
    multiplicative:
      max: 5
      min: 0.1

# Model architecture - original NESYMRES parameters
architecture:
  sinuisodal_embeddings: False
  dec_pf_dim: 512
  dec_layers: 5
  dim_hidden: 512
  lr: 0.0001
  dropout: 0
  num_features: 10
  ln: True
  N_p: 0
  num_inds: 50
  activation: "relu"
  bit16: True
  norm: True
  linear: False
  input_normalization: False
  src_pad_idx: 0
  trg_pad_idx: 0
  length_eq: 60
  n_l_enc: 5
  mean: 0.5  
  std: 0.5 
  dim_input: 4
  num_heads: 8
  output_dim: 60

# Inference configuration (for evaluation)
inference:
  beam_configs:
    - beam_size: 1
      length_penalty: 1.0
      max_len: 50
    - beam_size: 3
      length_penalty: 1.0
      max_len: 75
    - beam_size: 5
      length_penalty: 1.0
      max_len: 100
    - beam_size: 10
      length_penalty: 1.0
      max_len: 150
  bfgs:
    activated: True
    n_restarts: 10
    add_coefficients_if_not_existing: False
    normalization_o: False
    idx_remove: True
    normalization_type: MSE
    stop_time: 1e9

# Hydra configuration for output directory structure
hydra:
  run:
    dir: run/${dataset_train.predict_c}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
      dir: runs/${dataset_train.predict_c}/${now:%Y-%m-%d}/${now:%H-%M-%S}
