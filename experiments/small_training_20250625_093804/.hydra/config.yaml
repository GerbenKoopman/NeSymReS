train_path: ../data/raw_datasets/debug/10
val_path: ../data/raw_datasets/debug/5
raw_test_path: data/raw_datasets/150
test_path: data/validation
model_path: /local/home/lbiggio/NeuralSymbolicRegressionThatScales/weights/10MCompleted.ckpt
wandb: false
wandb_project: nesymres
num_of_workers: 2
batch_size: 4
epochs: 5
val_check_interval: 1.0
precision: 32
gpu: 1
random_seed: 42
output_dir: experiments
experiment_name: default
enable_checkpointing: true
save_top_k: 1
early_stopping_patience: 3
early_stopping_min_delta: 0.001
log_every_n_steps: 10
gradient_clip_val: 1.0
accumulate_grad_batches: 1
resume_from_checkpoint: null
logging:
  tensorboard: true
  wandb:
    enabled: ${wandb}
    project: ${wandb_project}
    tags:
    - default
    - unified
dataset_train:
  total_variables: null
  total_coefficients: null
  max_number_of_points: 200
  type_of_sampling_points: logarithm
  predict_c: true
  fun_support:
    max: 10
    min: -10
  constants:
    num_constants: 3
    additive:
      max: 2
      min: -2
    multiplicative:
      max: 2
      min: -2
dataset_val:
  total_variables: null
  total_coefficients: null
  max_number_of_points: 100
  type_of_sampling_points: constant
  predict_c: true
  fun_support:
    max: 10
    min: -10
  constants:
    num_constants: 3
    additive:
      max: 2
      min: -2
    multiplicative:
      max: 5
      min: -5
dataset_test:
  total_variables: null
  total_coefficients: null
  max_number_of_points: 200
  type_of_sampling_points: constant
  predict_c: true
  fun_support:
    max: 10
    min: -10
  constants:
    num_constants: 3
    additive:
      max: 2
      min: -2
    multiplicative:
      max: 2
      min: -2
data:
  train_path: ${train_path}
  val_path: ${val_path}
  test_path: ${test_path}
  num_workers: ${num_of_workers}
  batch_size: ${batch_size}
  dataset_train: ${dataset_train}
  dataset_val: ${dataset_val}
  dataset_test: ${dataset_test}
architecture:
  num_of_points: 200
  activation_name: gelu
  activation_token: 7
  positional_embedding_num: 20
  encoder:
    num_encoder_layer: 2
    hidden_size: 256
    num_hidden_layer_encoder: 2
    num_heads: 4
    ffn_hidden_size: 2048
    dropout: 0.0
  decoder:
    num_decoder_layer: 2
    hidden_size: 256
    num_hidden_layer_decoder: 2
    num_heads: 4
    ffn_hidden_size: 2048
    dropout: 0.0
inference:
  beam_size: 10
  beam_configs:
  - beam_size: 1
    length_penalty: 1.0
    max_len: 50
  - beam_size: 3
    length_penalty: 1.0
    max_len: 75
  - beam_size: 5
    length_penalty: 1.0
    max_len: 100
  - beam_size: 10
    length_penalty: 1.0
    max_len: 150
  bfgs:
    activated: true
    n_restarts: 10
    add_coefficients_if_not_existing: true
    normalization_o: 0
    idx_remove: null
    normalization_type: median
    stop_time: 100000
ablation:
  enabled: false
  studies:
  - name: beam_size_study
    parameter: inference.beam_size
    values:
    - 1
    - 3
    - 5
    - 10
    - 20
  - name: hidden_size_study
    parameter: architecture.encoder.hidden_size
    values:
    - 256
    - 512
    - 1024
finetune:
  enabled: false
  base_model_path: ${model_path}
  learning_rate: 1.0e-05
  freeze_encoder: false
  freeze_layers: []
  target_datasets: []
evaluation:
  metrics:
  - mse
  - r2
  - exact_match
  save_predictions: true
  save_detailed_results: true
  compare_with_baselines: false
